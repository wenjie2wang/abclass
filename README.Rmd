---
title: abclass
output: github_document
---

[![CRAN_Status_Badge](https://www.r-pkg.org/badges/version/abclass)](https://CRAN.R-project.org/package=abclass)
[![Build Status](https://github.com/wenjie2wang/abclass/workflows/R-CMD-check/badge.svg)](https://github.com/wenjie2wang/abclass/actions)
[![codecov](https://codecov.io/gh/wenjie2wang/abclass/branch/main/graph/badge.svg)](https://codecov.io/gh/wenjie2wang/abclass)


The package **abclass** provides implementations of the multi-category
angle-based classifiers (Zhang & Liu, 2014) with the large-margin unified
machines (Liu, et al., 2011) for high-dimensional data.

## Installation

One can install the released version from
[CRAN](https://CRAN.R-project.org/package=abclass).

``` r
install.packages("abclass")
```

Alternatively, the version under development can be installed as follows:

``` r
if (! require(remotes)) install.packages("remotes")
remotes::install_github("wenjie2wang/abclass", upgrade = "never")
```

## Getting Started

A toy example is as follows:

```{r example-abclass}
library(abclass)
set.seed(123)

## follow example 1 in Zhang and Liu (2014)
ntrain <- 100 # size of training set
ntest <- 1000 # size of testing set
p <- 100      # number of predictors
k <- 5        # number of categories

n <- ntrain + ntest
train_idx <- seq_len(ntrain)
y <- sample(k, size = n, replace = TRUE)       # response
mu <- matrix(rnorm(p * k), nrow = k, ncol = p) # mean vector
## normalize the mean vector so that they are distributed on the unit circle
mu <- mu / apply(mu, 1, function(a) sqrt(sum(a ^ 2)))
x <- t(sapply(y, function(i) rnorm(p, mean = mu[i, ], sd = 0.25)))
train_x <- x[train_idx, ]
test_x <- x[- train_idx, ]
y <- factor(paste0("label_", y))
train_y <- y[train_idx]
test_y <- y[- train_idx]

## model 1 with logistic deviance loss
model1 <- abclass(train_x, train_y, nfolds = 3)
pred1 <- predict(model1, test_x)
table(test_y, pred1)
mean(test_y == pred1) # accuracy

## model 2 with exponential loss approximating AdaBoost
model2 <- abclass(train_x, train_y, nlambda = 100, nfolds = 3, loss = "boost")
pred2 <- predict(model2, test_x)
table(test_y, pred2)
mean(test_y == pred2) # accuracy

## model 3 with hybrid hinge-boost loss
model3 <- abclass(train_x, train_y, nfolds = 3, loss = "hinge-boost",
                  lambda_min_ratio = 1e-3)
pred3 <- predict(model3, test_x)
table(test_y, pred3)
mean(test_y == pred3) # accuracy

## model 4 with the large-margin unified machines
model4 <- abclass(train_x, train_y, nfolds = 3, loss = "lum",
                  alpha = 0.1, lambda_min_ratio = 1e-3)
pred4 <- predict(model4, test_x)
table(test_y, pred4)
mean(test_y == pred4) # accuracy
```

## References

Zhang, C., & Liu, Y. (2014). Multicategory Angle-Based Large-Margin
Classification. \emph{Biometrika}, 101(3), 625--640.

Liu, Y., Zhang, H. H., & Wu, Y. (2011). Hard or soft classification?
large-margin unified machines. \emph{Journal of the American Statistical
Association}, 106(493), 166--177.

## License

[GNU General Public License](https://www.gnu.org/licenses/) (â‰¥ 3)

Copyright holder: Eli Lilly and Company
